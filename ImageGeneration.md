
# Image Generation
### ðŸ“ŒControllable Generation
- ControlNeXt: Powerful and Efficient Control for Image and Video Generation`[SD]` `[2024.08]` \[[paper](https://arxiv.org/abs/2408.06070)\] \[[code](https://github.com/dvlab-research/ControlNeXt)\]
- Eliminating Oversaturation and Artifacts of High Guidance Scales in Diffusion Models `[SD]` `[2024.10]` \[[paper](https://arxiv.org/abs/2410.02416)\]
- Improving Long-Text Alignment for Text-to-Image Diffusion Models`[SD]` `[2024.10]` \[[paper](https://arxiv.org/abs/2410.11817)\] \[[code](https://github.com/luping-liu/LongAlign)\]
- Diversity-Rewarded CFG Distillation `[2024.08]` \[[paper](https://arxiv.org/abs/2410.06084)\]
- InstanceDiffusion:Instance-levelÂ ControlÂ forÂ ImageÂ Generation`[SD]` `[2024.02]` \[[paper](https://arxiv.org/abs/2402.03290)\] \[[code](https://github.com/frank-xwang/InstanceDiffusion)\]
- IFAdapter: Instance feature control for grounded Text-to-Image Generation `[SD]` `[2024.09]` \[[paper](https://arxiv.org/abs/2409.08240)\]

### ðŸ“ŒSuper Resolution
- MegaFusion: Extend Diffusion Models towards Higher-resolution Image Generation without Further Tuning`[SD]` `[2024.08]` \[[paper](https://arxiv.org/abs/2408.11001)\] \[[code](https://haoningwu3639.github.io/MegaFusion)\]

### ðŸ“ŒMultiModal
- Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation `[AR]` `[2024.10]` \[[paper](https://arxiv.org/abs/2410.13848)\] \[[paper analysis](https://mickeyding.github.io/post/%E3%80%90-lun-wen-yue-du-%E3%80%91Janus-%20Decoupling%20Visual%20Encoding%20for%20Unified%20Multimodal%20Understanding%20and%20Generation.html)\]
- MONOFORMER: ONE TRANSFORMER FOR BOTH DIFFUSION AND AUTOREGRESSION `[SD+AR]` `[2024.10]` \[[paper](https://arxiv.org/abs/2409.16280)\] \[[code](https://github.com/MonoFormer/MonoFormer)\] \[[paper analysis](https://mickeyding.github.io/post/%E3%80%90-lun-wen-yue-du-%E3%80%91MONOFORMER-%20ONE%20TRANSFORMER%20FOR%20BOTH%20DIFFUSION%20AND%20AUTOREGRESSION.html)\]
- SHOW-O: ONE SINGLE TRANSFORMER TO UNIFY MULTIMODAL UNDERSTANDING AND GENERATION `[SD+AR]` `[2024.08]` \[[paper](https://arxiv.org/abs/2408.12528)\] \[[code](https://github.com/showlab/Show-o)\] \[[paper analysis](https://mickeyding.github.io/post/%E3%80%90-lun-wen-yue-du-%E3%80%91Show-o-%20ONE%20SINGLE%20TRANSFORMER%20TO%20UNIFY%20MULTIMODAL%20UNDERSTANDING%20AND%20GENERATION.html)\] 
  

### ðŸ“ŒAutoregressive Generation
- DART: DENOISING AUTOREGRESSIVE TRANSFORMER FOR SCALABLE TEXT-TO-IMAGE GENERATION `[SD+AR]` `[2024.10]` \[[paper](https://arxiv.org/abs/2410.08159)\]
- Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens `[AR]` `[2024.10]` \[[paper](https://arxiv.org/pdf/2410.13863)\]
### ðŸ“ŒEfficiency 
- Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think `[DiT]` `[2024.10]` \[[paper](https://arxiv.org/abs/2410.06940)\]
- SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers `[DiT]` `[2024.10]` \[[paper](https://arxiv.org/abs/2410.10629)\]
- RECTIFIED DIFFUSION: STRAIGHTNESS IS NOT YOUR NEED IN RECTIFIED FLOW `[SD]` `[2024.10]` \[[paper](https://arxiv.org/pdf/2410.07303)\]
- Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models `[CM]` `[2024.10]` \[[paper](https://arxiv.org/abs/2410.11081)\]

### ðŸ“ŒDataset Expansion
- Scalable Ranked Preference Optimization for Text-to-Image Generation `[SD]` `[2024.10]` \[[paper](https://arxiv.org/pdf/2410.18013)\]